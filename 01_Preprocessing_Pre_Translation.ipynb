{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install emoji"
      ],
      "metadata": {
        "id": "hdGu9hfssvrw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AAw2E_JUtUzm"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fVB_Ra2stF4e"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "import emoji"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "B9RfkaM02cxv"
      },
      "outputs": [],
      "source": [
        "current_language='XX' #Set to current language\n",
        "\n",
        "#File paths: Adjust to relevant paths\n",
        "file1 = '/en/refugee_OR_refugees_OR_refugees_OR_refugees_OR_Ref - Feb 27, 2024 - 3 27 39 PM.xlsx'\n",
        "file2 = '/en/refugee_OR_refugees_OR_refugees_OR_refugees_OR_Ref - Feb 27, 2024 - 3 30 39 PM.xlsx'\n",
        "file3 = '/en/refugee_OR_refugees_OR_refugees_OR_refugees_OR_Ref - Feb 27, 2024 - 3 35 31 PM.xlsx'\n",
        "file4 = '/en/refugee_OR_refugees_OR_refugees_OR_refugees_OR_Ref - Feb 27, 2024 - 3 39 03 PM.xlsx'\n",
        "file5 = '/en/refugee_OR_refugees_OR_refugees_OR_refugees_OR_Ref - Feb 27, 2024 - 3 43 56 PM.xlsx'\n",
        "\n",
        "data = [file1, file2, file3, file4, file5]\n",
        "\n",
        "df_en = pd.concat((pd.read_excel(path+file) for file in data_english), ignore_index=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qMxpudnHbAp0"
      },
      "source": [
        "# 02 Check data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "J_Mp8KKDB_F6"
      },
      "outputs": [],
      "source": [
        "# Check for duplicate rows and count them\n",
        "num_duplicates = df.duplicated().sum()\n",
        "print(\"Number of duplicate rows in the DataFrame:\", num_duplicates)\n",
        "\n",
        "# Hit sentence duplicates\n",
        "num_duplicates_column_HitSentence = df['Hit Sentence'].duplicated().sum()\n",
        "print(\"Number of duplicates in column 'Hit Sentence':\", num_duplicates_column_HitSentence)\n",
        "\n",
        "# URL duplicates\n",
        "num_duplicates_column_URL = df['URL'].duplicated().sum()\n",
        "print(\"Number of duplicates in column 'URL':\", num_duplicates_column_URL)\n",
        "\n",
        "#Check sources\n",
        "source_counts = df['Source'].value_counts()\n",
        "print(source_counts)\n",
        "\n",
        "# Keep rows where source is 'Twitter'\n",
        "df = df[df['Source'] == 'Twitter']\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OwHnCgwV7PfY"
      },
      "outputs": [],
      "source": [
        "#Check Language\n",
        "language_counts = df['Language'].value_counts()\n",
        "\n",
        "print(language_counts)\n",
        "\n",
        "# Keep rows where language is the current language\n",
        "df = df[df['Language'] == current_language]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OuX067Wo4GlH"
      },
      "outputs": [],
      "source": [
        "# Find the maximum length of the 'Hit Sentence'\n",
        "max_length = df['Hit Sentence'].apply(lambda x: len(str(x))).max()\n",
        "\n",
        "print(\"Maximum length of 'Hit Sentence':\", max_length)\n",
        "\n",
        "# Find the minimum length of the 'Hit Sentence'\n",
        "min_length = df['Hit Sentence'].apply(lambda x: len(str(x))).min()\n",
        "\n",
        "print(\"Minimum length of 'Hit Sentence':\", min_length)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HWSa6N3tNu4N"
      },
      "source": [
        "# 03 EDA"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UfCHZcpbUXzi",
        "outputId": "16f32481-f99c-4990-c0b3-ca1caf2fdfd7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Date range:\n",
            "From: 2023-01-01 00:11:00\n",
            "To: 2023-12-31 23:50:00\n"
          ]
        }
      ],
      "source": [
        "# Print the date range\n",
        "date_range = pd.to_datetime(df['Date'])\n",
        "print(\"Date range:\")\n",
        "print(\"From:\", date_range.min())\n",
        "print(\"To:\", date_range.max())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MNwGgilI9_yJ"
      },
      "outputs": [],
      "source": [
        "# Convert 'Date' column to datetime format\n",
        "df['Date'] = pd.to_datetime(df['Date'])\n",
        "\n",
        "# Group data by date and count the number of tweets for each date\n",
        "tweet_counts = df.groupby(df['Date'].dt.date).size()\n",
        "\n",
        "# Plot the number of tweets over time\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.plot(tweet_counts.index, tweet_counts.values, linestyle='-')\n",
        "plt.title('Number of Tweets Over Time in English')\n",
        "plt.xlabel('Date')\n",
        "plt.ylabel('Number of Tweets')\n",
        "plt.xticks(rotation=45)\n",
        "plt.grid(True)\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ajesIrivvo3w"
      },
      "outputs": [],
      "source": [
        "# Smooth the line using a 7-day moving average\n",
        "smoothed_tweet_counts = tweet_counts.rolling(window=7).mean()\n",
        "\n",
        "# Plot the smoothed number of tweets over time\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.plot(smoothed_tweet_counts.index, smoothed_tweet_counts.values, linewidth=2)\n",
        "plt.title('Smoothed Number of Tweets Over Time in English', fontsize=16)\n",
        "plt.xlabel('Date', fontsize=12)\n",
        "plt.ylabel('Smoothed Number of Tweets', fontsize=12)\n",
        "plt.xticks(rotation=45, fontsize=10)\n",
        "plt.yticks(fontsize=10)\n",
        "plt.grid(True, linestyle='--', alpha=0.7)\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vVPKdzj9f0-O"
      },
      "outputs": [],
      "source": [
        "country_counts = df['Country'].value_counts()\n",
        "print(country_counts)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NFjBsZItOTnG"
      },
      "source": [
        "Identify similar tweets, which are often just Retweets (\"RT\") or Quote Tweets (\"QT\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FwEF-avnOQER"
      },
      "outputs": [],
      "source": [
        "# Count tweets that start with \"QT\"\n",
        "num_qt_tweets = (df['Hit Sentence'].str.startswith('QT')).sum()\n",
        "print(\"Number of tweets starting with 'QT':\", num_qt_tweets)\n",
        "\n",
        "# Count tweets that start with \"RT\"\n",
        "num_qt_tweets = (df['Hit Sentence'].str.startswith('RT')).sum()\n",
        "print(\"Number of tweets starting with 'RT':\", num_qt_tweets)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Wbpc3yygILLW"
      },
      "outputs": [],
      "source": [
        "sentiment_counts = df['Sentiment'].value_counts()\n",
        "\n",
        "# Pie plot\n",
        "plt.figure(figsize=(8, 6))\n",
        "plt.pie(sentiment_counts, labels=sentiment_counts.index, autopct='%1.1f%%', startangle=140)\n",
        "plt.title('Sentiment Distribution Swedish')\n",
        "plt.axis('equal')\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3wx9RXz8epmq"
      },
      "source": [
        "# 04 Clean data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0NW_4TYIMoL-"
      },
      "outputs": [],
      "source": [
        "# Remove duplicate rows\n",
        "df = df.drop_duplicates()\n",
        "\n",
        "# Remove url duplicates\n",
        "df = df.drop_duplicates(subset=['Hit Sentence'])\n",
        "\n",
        "# Drop rows with NaN values in 'Hit Sentence' column from the original DataFrame\n",
        "df = df.dropna(subset=['Hit Sentence'])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DrBCIclfexXe"
      },
      "outputs": [],
      "source": [
        "# Drop columns\n",
        "Echo_columns_to_drop = ['Social Echo Total','Editorial Echo','Twitter Social Echo', 'Facebook Social Echo','Reddit Social Echo']\n",
        "Engagement_columns_to_drop = ['Views', 'Likes', 'Replies', 'Retweets', 'Comments', 'Shares', 'Reactions', 'Engagement', 'Estimated Views']\n",
        "Other_columns_to_drop =['Desktop Reach', 'Mobile Reach', 'National Viewership', 'AVE', 'Reach', 'Headline', 'Opening Text', 'Source', 'Document Tags']\n",
        "\n",
        "Twitter_columns_to_drop = ['Twitter Authority', 'Twitter Followers', 'Twitter Following', 'Twitter Id' , 'Twitter Client',  'Twitter Screen Name', 'Twitter Bio']\n",
        "User_columns_to_drop = ['Country', 'State','City', 'Subregion', 'Influencer', 'User Profile Url', 'Threads', 'Is Verified']\n",
        "Tweet_columns_to_drop = ['Tweet Id', 'Parent URL' , 'Key Phrases', 'Document ID']\n",
        "\n",
        "UNHCR_columns_to_drop = ['Input Name', 'Keywords', 'Alternate Date Format', 'Time']\n",
        "\n",
        "df_clean = df[:]\n",
        "\n",
        "df_clean = df.drop(columns=Echo_columns_to_drop)\n",
        "df_clean = df_clean.drop(columns=Engagement_columns_to_drop)\n",
        "df_clean = df_clean.drop(columns=Other_columns_to_drop)\n",
        "\n",
        "df_clean = df_clean.drop(columns=Twitter_columns_to_drop)\n",
        "df_clean = df_clean.drop(columns=User_columns_to_drop)\n",
        "df_clean = df_clean.drop(columns=Tweet_columns_to_drop)\n",
        "\n",
        "df_clean = df_clean.drop(columns=UNHCR_columns_to_drop)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2Py5tv2pS5lQ"
      },
      "source": [
        "## 04 Text processing - mentions and hashtags"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Zvh7-tyIS9-t"
      },
      "outputs": [],
      "source": [
        "df_new =  df_clean[:]\n",
        "\n",
        "# Replace mentions starting with '@' with '@USER'\n",
        "df_new['Hit Sentence'] = df_new['Hit Sentence'].str.replace(r'@\\w+', '@USER')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TYe7gdN1UP2g"
      },
      "outputs": [],
      "source": [
        "# Function to transform emojis into text\n",
        "def transform_emojis(text):\n",
        "    return emoji.demojize(text)\n",
        "\n",
        "# Apply the function to the 'Hit Sentence' column\n",
        "df_new['Hit Sentence'] = df_new['Hit Sentence'].apply(transform_emojis)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zDVz-1TUxlIn"
      },
      "outputs": [],
      "source": [
        "import re\n",
        "\n",
        "# Define a regex pattern to match URLs\n",
        "url_pattern = r'https?://\\S+|www\\.\\S+'\n",
        "\n",
        "# Function to replace URLs with 'URL'\n",
        "def replace_urls_with_url(text):\n",
        "    return re.sub(url_pattern, 'URL', text)\n",
        "\n",
        "# Apply the function to the 'Hit Sentence' column\n",
        "df_new['Hit Sentence'] = df_new['Hit Sentence'].apply(replace_urls_with_url)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DNZoIfmSOle2"
      },
      "source": [
        "#Sample tweets for the labelling process"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ALViXkr4tgkn"
      },
      "outputs": [],
      "source": [
        "# Shuffle the rows in df_test\n",
        "df_shuffled = df_new.sample(frac=1, random_state=42)\n",
        "\n",
        "# Reset the index of the shuffled DataFrame\n",
        "df_shuffled.reset_index(drop=True, inplace=True)\n",
        "df_shuffled.head()\n",
        "\n",
        "# Sample 600 random rows\n",
        "df_sampled = df_shuffled.sample(n=600, random_state=42)\n",
        "df_sampled.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gk9scNsyvfLE"
      },
      "outputs": [],
      "source": [
        "# Group data by date and count the number of tweets for each date\n",
        "tweet_counts = df_sampled.groupby(df_sampled['Date'].dt.date).size()\n",
        "\n",
        "# Plot the number of tweets over time\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.plot(tweet_counts.index, tweet_counts.values, linestyle='-')\n",
        "plt.title('Number of Tweets Over Time in the sample')\n",
        "plt.xlabel('Date')\n",
        "plt.ylabel('Number of Tweets')\n",
        "plt.xticks(rotation=45)\n",
        "plt.grid(True)\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sBhFQF3cu9lg"
      },
      "outputs": [],
      "source": [
        "# Save the sampled DataFrame to a CSV file\n",
        "df_sampled.to_csv('/content/drive/MyDrive/CBS Thesis Lydia & Sara/Data/Data_Labeling/XX', sep='\\t', encoding='utf-16', index=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Saving the non-sampled tweets to another file:"
      ],
      "metadata": {
        "id": "S6lesT5oMQdF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_new = df_new[~df_new['URL'].isin(df_sampled['URL'])]\n",
        "\n",
        "# Save the DataFrame to a CSV file in Google Drive\n",
        "df_new.to_csv('/content/drive/MyDrive/CBS Thesis Lydia & Sara/Data/03_Data_Modeling/XX.csv', sep='\\t', encoding='utf-16', index=False)"
      ],
      "metadata": {
        "id": "_PkzqiIaMPE2"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}